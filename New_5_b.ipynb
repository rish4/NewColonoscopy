{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New-5-b.ipynb",
      "provenance": [],
      "mount_file_id": "19WZxgfhkOYsi-_MWgR2xfN3q_4V_1Pit",
      "authorship_tag": "ABX9TyMMBAad5CxEeZ350NDmw+AK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rish4/NewColonoscopy/blob/main/New_5_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01a_ApbSt_kw"
      },
      "source": [
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import auc\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras import metrics\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.metrics import AUC\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from keras import models\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\r\n",
        "import numpy as np\r\n",
        "from keras.preprocessing import image\r\n",
        "from IPython.display import display\r\n",
        "from PIL import Image\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLrMRLVeuI5V"
      },
      "source": [
        "## Set file paths to image files\r\n",
        "\r\n",
        "train_path = \"/content/drive/MyDrive/NewDB/Training set\"\r\n",
        "test_path = \"/content/drive/MyDrive/NewDB/Test set\"\r\n",
        "\r\n",
        "## Set up hyperparameters that will be used later\r\n",
        "hyper_dimension = 64\r\n",
        "hyper_batch_size = 32\r\n",
        "hyper_epochs = 100\r\n",
        "hyper_channels = 3\r\n",
        "hyper_mode = 'rgb'\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Wnps0zhMuXjB",
        "outputId": "dcf201c9-7284-4ec5-fb36-ff78645411cd"
      },
      "source": [
        "\r\n",
        "'''cnn_model = cnn.fit_generator(train_generator, \r\n",
        "                              steps_per_epoch = len(train_generator), \r\n",
        "                              epochs = 20, \r\n",
        "                              validation_data = test_generator,\r\n",
        "                              validation_steps = len(test_generator)\r\n",
        "                              )'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cnn_model = cnn.fit_generator(train_generator, \\n                              steps_per_epoch = len(train_generator), \\n                              epochs = 20, \\n                              validation_data = test_generator,\\n                              validation_steps = len(test_generator)\\n                              )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj3jiCiH3_0z"
      },
      "source": [
        "**For checking best epochs and batch size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ-_0LWFuJ-Q",
        "outputId": "1db7e7b5-3b6d-4576-96a7-c5557bbacd8e"
      },
      "source": [
        "def create_model():\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0)\r\n",
        "\r\n",
        "batch_size = [10,16,32,40]\r\n",
        "epochs = [10, 20,50]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(epochs=epochs, batch_size=batch_size)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.721212 using {'batch_size': 16, 'epochs': 20}\n",
            "0.657576 (0.029998) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.533333 (0.059997) with: {'batch_size': 10, 'epochs': 20}\n",
            "0.690909 (0.077139) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.406061 (0.037360) with: {'batch_size': 16, 'epochs': 10}\n",
            "0.721212 (0.066942) with: {'batch_size': 16, 'epochs': 20}\n",
            "0.627273 (0.063420) with: {'batch_size': 16, 'epochs': 50}\n",
            "0.600000 (0.146210) with: {'batch_size': 32, 'epochs': 10}\n",
            "0.630303 (0.190885) with: {'batch_size': 32, 'epochs': 20}\n",
            "0.690909 (0.107052) with: {'batch_size': 32, 'epochs': 50}\n",
            "0.536364 (0.115708) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.569697 (0.162849) with: {'batch_size': 40, 'epochs': 20}\n",
            "0.693939 (0.183377) with: {'batch_size': 40, 'epochs': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IWh0NJ04KwM"
      },
      "source": [
        "**For checking best optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6b9-qOChi9S",
        "outputId": "02418d6c-f030-4044-b179-5aa48dba7387"
      },
      "source": [
        "def create_model(optimizer='adam'):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=16, epochs=20)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(optimizer=optimizer)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.721212 using {'optimizer': 'Nadam'}\n",
            "0.660606 (0.148701) with: {'optimizer': 'SGD'}\n",
            "0.600000 (0.146210) with: {'optimizer': 'RMSprop'}\n",
            "0.566667 (0.101323) with: {'optimizer': 'Adagrad'}\n",
            "0.460606 (0.215301) with: {'optimizer': 'Adadelta'}\n",
            "0.509091 (0.205704) with: {'optimizer': 'Adam'}\n",
            "0.563636 (0.025713) with: {'optimizer': 'Adamax'}\n",
            "0.721212 (0.066942) with: {'optimizer': 'Nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G65wW4nh4P59"
      },
      "source": [
        "**For checking best weight initializer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZirnFhcx6gW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30925829-b84f-436e-8730-dc7d427bd590"
      },
      "source": [
        "def create_model(init_mode='uniform'):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=16, epochs=20)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(init_mode=init_mode)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.718182 using {'init_mode': 'normal'}\n",
            "0.530303 (0.077258) with: {'init_mode': 'uniform'}\n",
            "0.530303 (0.077258) with: {'init_mode': 'lecun_uniform'}\n",
            "0.718182 (0.012857) with: {'init_mode': 'normal'}\n",
            "0.657576 (0.080060) with: {'init_mode': 'zero'}\n",
            "0.600000 (0.146210) with: {'init_mode': 'glorot_normal'}\n",
            "0.527273 (0.097348) with: {'init_mode': 'glorot_uniform'}\n",
            "0.466667 (0.059997) with: {'init_mode': 'he_normal'}\n",
            "0.654545 (0.053526) with: {'init_mode': 'he_uniform'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEfRmpI74Uxb"
      },
      "source": [
        "**For checking best activation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKotUy_m25KP",
        "outputId": "c9e9fcbb-31ad-474a-8d18-a13dd630086d"
      },
      "source": [
        "def create_model(activation='relu'):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=16, epochs=20)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(activation=activation)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.718182 using {'activation': 'hard_sigmoid'}\n",
            "0.596970 (0.104006) with: {'activation': 'softmax'}\n",
            "0.600000 (0.146210) with: {'activation': 'softplus'}\n",
            "0.500000 (0.037113) with: {'activation': 'softsign'}\n",
            "0.630303 (0.119994) with: {'activation': 'relu'}\n",
            "0.660606 (0.148701) with: {'activation': 'tanh'}\n",
            "0.527273 (0.143164) with: {'activation': 'sigmoid'}\n",
            "0.718182 (0.012857) with: {'activation': 'hard_sigmoid'}\n",
            "0.624242 (0.076181) with: {'activation': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_szaBzC7oVc"
      },
      "source": [
        "**For checking best filters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ii8QlD9368W",
        "outputId": "463524fb-5883-4594-a7a2-c69ec7a75441"
      },
      "source": [
        "def create_model(filters=16):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=16, epochs=20)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "filters=[4,8,16,32,64,80,128]\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(filters=filters)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.751515 using {'filters': 16}\n",
            "0.627273 (0.063420) with: {'filters': 4}\n",
            "0.500000 (0.037113) with: {'filters': 8}\n",
            "0.751515 (0.034284) with: {'filters': 16}\n",
            "0.663636 (0.167134) with: {'filters': 32}\n",
            "0.527273 (0.143164) with: {'filters': 64}\n",
            "0.600000 (0.146210) with: {'filters': 80}\n",
            "0.663636 (0.167134) with: {'filters': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIhYITEa7r3a"
      },
      "source": [
        "**For checking best kernel size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euAkrSKT47Zs",
        "outputId": "00d67fb9-c208-4f06-da2e-32504a9b162f"
      },
      "source": [
        "def create_model(kernel_size=3):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=16, epochs=20)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "kernel_size=[2,3,5,7,9,11,13]\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(kernel_size=kernel_size)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.627273 using {'kernel_size': 13}\n",
            "0.463636 (0.188221) with: {'kernel_size': 2}\n",
            "0.600000 (0.146210) with: {'kernel_size': 3}\n",
            "0.627273 (0.063420) with: {'kernel_size': 5}\n",
            "0.596970 (0.104006) with: {'kernel_size': 7}\n",
            "0.469697 (0.077258) with: {'kernel_size': 9}\n",
            "0.527273 (0.143164) with: {'kernel_size': 11}\n",
            "0.627273 (0.122643) with: {'kernel_size': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sHKbQjm55zP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}