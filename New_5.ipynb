{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New-5.ipynb",
      "provenance": [],
      "mount_file_id": "19WZxgfhkOYsi-_MWgR2xfN3q_4V_1Pit",
      "authorship_tag": "ABX9TyOdNtXz3w6gOuKPMkZIYIf+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rish4/NewColonoscopy/blob/main/New_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01a_ApbSt_kw"
      },
      "source": [
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import auc\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras import metrics\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.metrics import AUC\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from keras import models\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\r\n",
        "import numpy as np\r\n",
        "from keras.preprocessing import image\r\n",
        "from IPython.display import display\r\n",
        "from PIL import Image\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "import numpy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLrMRLVeuI5V"
      },
      "source": [
        "## Set file paths to image files\r\n",
        "\r\n",
        "train_path = \"/content/drive/MyDrive/NewDB/Training set\"\r\n",
        "test_path = \"/content/drive/MyDrive/NewDB/Test set\"\r\n",
        "\r\n",
        "## Set up hyperparameters that will be used later\r\n",
        "hyper_dimension = 64\r\n",
        "hyper_batch_size = 32\r\n",
        "hyper_epochs = 100\r\n",
        "hyper_channels = 3\r\n",
        "hyper_mode = 'rgb'\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Wnps0zhMuXjB",
        "outputId": "dcf201c9-7284-4ec5-fb36-ff78645411cd"
      },
      "source": [
        "\r\n",
        "'''cnn_model = cnn.fit_generator(train_generator, \r\n",
        "                              steps_per_epoch = len(train_generator), \r\n",
        "                              epochs = 20, \r\n",
        "                              validation_data = test_generator,\r\n",
        "                              validation_steps = len(test_generator)\r\n",
        "                              )'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cnn_model = cnn.fit_generator(train_generator, \\n                              steps_per_epoch = len(train_generator), \\n                              epochs = 20, \\n                              validation_data = test_generator,\\n                              validation_steps = len(test_generator)\\n                              )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj3jiCiH3_0z"
      },
      "source": [
        "**For checking best epochs and batch size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ-_0LWFuJ-Q",
        "outputId": "1d166b73-3f09-44e7-b21f-d117013782c3"
      },
      "source": [
        "def create_model():\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0)\r\n",
        "\r\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(epochs=epochs, batch_size=batch_size)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.787879 using {'batch_size': 40, 'epochs': 100}\n",
            "0.533333 (0.120909) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.593939 (0.111423) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.627273 (0.122643) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.463636 (0.115708) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.627273 (0.122643) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.627273 (0.122643) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.566667 (0.101323) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.751515 (0.081762) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.787879 (0.154516) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.466667 (0.059997) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.724242 (0.193608) with: {'batch_size': 60, 'epochs': 50}\n",
            "0.727273 (0.222681) with: {'batch_size': 60, 'epochs': 100}\n",
            "0.657576 (0.029998) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.660606 (0.148701) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.693939 (0.183377) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.563636 (0.078554) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.566667 (0.101323) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.693939 (0.183377) with: {'batch_size': 100, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IWh0NJ04KwM"
      },
      "source": [
        "**For checking best optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6b9-qOChi9S",
        "outputId": "7f440506-b812-477f-85e6-2ca9f1bac5b8"
      },
      "source": [
        "def create_model(optimizer='adam'):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=40, epochs=100)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(optimizer=optimizer)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.757576 using {'optimizer': 'Adagrad'}\n",
            "0.660606 (0.148701) with: {'optimizer': 'SGD'}\n",
            "0.727273 (0.222681) with: {'optimizer': 'RMSprop'}\n",
            "0.757576 (0.186800) with: {'optimizer': 'Adagrad'}\n",
            "0.724242 (0.144758) with: {'optimizer': 'Adadelta'}\n",
            "0.693939 (0.183377) with: {'optimizer': 'Adam'}\n",
            "0.690909 (0.107052) with: {'optimizer': 'Adamax'}\n",
            "0.627273 (0.122643) with: {'optimizer': 'Nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G65wW4nh4P59"
      },
      "source": [
        "**For checking best weight initializer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZirnFhcx6gW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b635f7-f6fe-469f-d433-ae4f62a66562"
      },
      "source": [
        "def create_model(init_mode='uniform'):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=40, epochs=100)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(init_mode=init_mode)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.757576 using {'init_mode': 'uniform'}\n",
            "0.757576 (0.186800) with: {'init_mode': 'uniform'}\n",
            "0.660606 (0.148701) with: {'init_mode': 'lecun_uniform'}\n",
            "0.727273 (0.222681) with: {'init_mode': 'normal'}\n",
            "0.624242 (0.149440) with: {'init_mode': 'zero'}\n",
            "0.693939 (0.183377) with: {'init_mode': 'glorot_normal'}\n",
            "0.693939 (0.150359) with: {'init_mode': 'glorot_uniform'}\n",
            "0.657576 (0.080060) with: {'init_mode': 'he_normal'}\n",
            "0.660606 (0.105322) with: {'init_mode': 'he_uniform'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEfRmpI74Uxb"
      },
      "source": [
        "**For checking best activation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKotUy_m25KP",
        "outputId": "fd5924b9-ac9c-4abe-b8cf-6b675b433e90"
      },
      "source": [
        "def create_model(activation='relu'):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=40, epochs=100)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(activation=activation)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.757576 using {'activation': 'softsign'}\n",
            "0.660606 (0.148701) with: {'activation': 'softmax'}\n",
            "0.660606 (0.148701) with: {'activation': 'softplus'}\n",
            "0.757576 (0.186800) with: {'activation': 'softsign'}\n",
            "0.627273 (0.122643) with: {'activation': 'relu'}\n",
            "0.593939 (0.111423) with: {'activation': 'tanh'}\n",
            "0.693939 (0.183377) with: {'activation': 'sigmoid'}\n",
            "0.693939 (0.183377) with: {'activation': 'hard_sigmoid'}\n",
            "0.693939 (0.183377) with: {'activation': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_szaBzC7oVc"
      },
      "source": [
        "**For checking best filters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ii8QlD9368W",
        "outputId": "015f0e66-0a15-497a-b5ee-4ce66911fe20"
      },
      "source": [
        "def create_model(filters=16):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=40, epochs=100)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "filters=[4,8,16,32,64,80,128]\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(filters=filters)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.727273 using {'filters': 8}\n",
            "0.693939 (0.183377) with: {'filters': 4}\n",
            "0.727273 (0.222681) with: {'filters': 8}\n",
            "0.660606 (0.148701) with: {'filters': 16}\n",
            "0.657576 (0.080060) with: {'filters': 32}\n",
            "0.727273 (0.222681) with: {'filters': 64}\n",
            "0.727273 (0.222681) with: {'filters': 80}\n",
            "0.727273 (0.222681) with: {'filters': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIhYITEa7r3a"
      },
      "source": [
        "**For checking best kernel size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euAkrSKT47Zs",
        "outputId": "1c3c4682-50fb-4f01-93da-6b6f33c5f7b2"
      },
      "source": [
        "def create_model(kernel_size=3):\r\n",
        "  cnn=Sequential()\r\n",
        "  cnn.add(InputLayer(input_shape=(hyper_dimension, hyper_dimension, hyper_channels)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\r\n",
        "  cnn.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "  cnn.add(Flatten())\r\n",
        "\r\n",
        "  cnn.add(Dense(activation='relu', units=128))\r\n",
        "  cnn.add(Dense(activation='sigmoid', units=1))\r\n",
        "\r\n",
        "  #cnn.summary()\r\n",
        "\r\n",
        "  cnn.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "  return cnn\r\n",
        "\r\n",
        "seed = 7\r\n",
        "numpy.random.seed(seed)\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0, \r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2, \r\n",
        "                                   horizontal_flip = True )\r\n",
        "\r\n",
        "#val_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0) \r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_path, \r\n",
        "                                                    target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                    batch_size = hyper_batch_size, \r\n",
        "                                                    color_mode = hyper_mode,\r\n",
        "                                                    class_mode = 'binary', \r\n",
        "                                                    seed = 42)\r\n",
        "\r\n",
        "test_generator = test_datagen.flow_from_directory(directory = test_path, \r\n",
        "                                                 target_size = (hyper_dimension, hyper_dimension),\r\n",
        "                                                 batch_size = hyper_batch_size, \r\n",
        "                                                 class_mode = 'binary',\r\n",
        "                                                 color_mode = hyper_mode,\r\n",
        "                                                 shuffle=False,\r\n",
        "                                                 seed = 42)\r\n",
        "\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "#datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "#dataset = datagen.flow_from_directory('dataset_dog_breeds/train/', class_mode='categorical')\r\n",
        "\r\n",
        "X, Y = train_generator.next()\r\n",
        "\r\n",
        "cnn = KerasClassifier(build_fn=create_model, verbose=0,batch_size=40, epochs=100)\r\n",
        "\r\n",
        "#batch_size = [10, 20, 40, 60, 80, 100]\r\n",
        "#epochs = [10, 50, 100]\r\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\r\n",
        "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\r\n",
        "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\r\n",
        "kernel_size=[2,3,5,7,9,11,13]\r\n",
        "\r\n",
        "'''param_grid = {\r\n",
        "    'batch_size': batch_size, \r\n",
        "    'epochs':epochs,\r\n",
        "    'optimizer': optimizer,\r\n",
        "    'init_mode': init_mode,\r\n",
        "    'activation': activation\r\n",
        "}'''\r\n",
        "\r\n",
        "param_grid= dict(kernel_size=kernel_size)\r\n",
        "grid = GridSearchCV(estimator=cnn, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
        "grid_result = grid.fit(X, Y)\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1656 images belonging to 2 classes.\n",
            "Found 415 images belonging to 2 classes.\n",
            "Best: 0.727273 using {'kernel_size': 9}\n",
            "0.660606 (0.105322) with: {'kernel_size': 2}\n",
            "0.721212 (0.124501) with: {'kernel_size': 3}\n",
            "0.660606 (0.148701) with: {'kernel_size': 5}\n",
            "0.657576 (0.080060) with: {'kernel_size': 7}\n",
            "0.727273 (0.222681) with: {'kernel_size': 9}\n",
            "0.596970 (0.104006) with: {'kernel_size': 11}\n",
            "0.693939 (0.183377) with: {'kernel_size': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sHKbQjm55zP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}